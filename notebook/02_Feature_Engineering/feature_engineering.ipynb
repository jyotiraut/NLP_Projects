{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e28caa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "import numpy as np\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c55d77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned and preprocessed data (e.g., from previous steps)\n",
    "df = pd.read_csv('../../data/clean/clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a6d3f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ability  able  aboutbr  abr  absolute  absolutely  absorb  absorption  \\\n",
      "0        0     0        0    0         0           0       0           0   \n",
      "1        0     0        0    0         0           0       0           0   \n",
      "2        0     0        0    0         0           0       0           0   \n",
      "3        0     0        0    0         0           0       0           0   \n",
      "4        0     0        0    0         0           0       0           0   \n",
      "\n",
      "   absurd  acai  ...  zesty  zevia  zico  zing  zinger  zip  ziplock  \\\n",
      "0       0     0  ...      0      0     0     0       0    0        0   \n",
      "1       0     0  ...      0      0     0     0       0    0        0   \n",
      "2       0     0  ...      0      0     0     0       0    0        0   \n",
      "3       0     0  ...      0      0     0     0       0    0        0   \n",
      "4       0     0  ...      0      0     0     0       0    0        0   \n",
      "\n",
      "   ziwipeak  zoe  zukes  \n",
      "0         0    0      0  \n",
      "1         0    0      0  \n",
      "2         0    0      0  \n",
      "3         0    0      0  \n",
      "4         0    0      0  \n",
      "\n",
      "[5 rows x 5000 columns]\n"
     ]
    }
   ],
   "source": [
    "# Initialize CountVectorizer\n",
    "count_vect = CountVectorizer(max_features=5000)\n",
    "bow_features = count_vect.fit_transform(df['processed_text'])\n",
    "\n",
    "# Optional: Convert to DataFrame for inspection\n",
    "bow_df = pd.DataFrame(bow_features.toarray(), columns=count_vect.get_feature_names_out())\n",
    "print(bow_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "183231eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ability  able  aboutbr  abr  absolute  absolutely  absorb  absorption  \\\n",
      "0      0.0   0.0      0.0  0.0       0.0         0.0     0.0         0.0   \n",
      "1      0.0   0.0      0.0  0.0       0.0         0.0     0.0         0.0   \n",
      "2      0.0   0.0      0.0  0.0       0.0         0.0     0.0         0.0   \n",
      "3      0.0   0.0      0.0  0.0       0.0         0.0     0.0         0.0   \n",
      "4      0.0   0.0      0.0  0.0       0.0         0.0     0.0         0.0   \n",
      "\n",
      "   absurd  acai  ...  zesty  zevia  zico  zing  zinger  zip  ziplock  \\\n",
      "0     0.0   0.0  ...    0.0    0.0   0.0   0.0     0.0  0.0      0.0   \n",
      "1     0.0   0.0  ...    0.0    0.0   0.0   0.0     0.0  0.0      0.0   \n",
      "2     0.0   0.0  ...    0.0    0.0   0.0   0.0     0.0  0.0      0.0   \n",
      "3     0.0   0.0  ...    0.0    0.0   0.0   0.0     0.0  0.0      0.0   \n",
      "4     0.0   0.0  ...    0.0    0.0   0.0   0.0     0.0  0.0      0.0   \n",
      "\n",
      "   ziwipeak  zoe  zukes  \n",
      "0       0.0  0.0    0.0  \n",
      "1       0.0  0.0    0.0  \n",
      "2       0.0  0.0    0.0  \n",
      "3       0.0  0.0    0.0  \n",
      "4       0.0  0.0    0.0  \n",
      "\n",
      "[5 rows x 5000 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf_vect = TfidfVectorizer(max_features=5000)\n",
    "tfidf_features = tfidf_vect.fit_transform(df['processed_text'])\n",
    "\n",
    "# Optional: Convert to DataFrame for inspection\n",
    "tfidf_df = pd.DataFrame(tfidf_features.toarray(), columns=tfidf_vect.get_feature_names_out())\n",
    "print(tfidf_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d833dbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a feature for the length of each review (number of words)\n",
    "df['review_length'] = df['processed_text'].apply(lambda x: len(x.split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0b5f420",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Lexicon \n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "df['vader_compound'] = df['processed_text'].apply(lambda x: sia.polarity_scores(x)['compound'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37b276b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Combine TF-IDF features and review length (as an example)\n",
    "X = hstack([tfidf_features, np.array(df['review_length']).reshape(-1, 1)])\n",
    "\n",
    "# If you want to add the VADER score as well:\n",
    "X = hstack([tfidf_features, \n",
    "            np.array(df['review_length']).reshape(-1, 1), \n",
    "            np.array(df['vader_compound']).reshape(-1, 1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c5c12ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features file saved: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Correct path: up two levels to reach project root, then into 'features/processed'\n",
    "processed_features_dir = os.path.join('..', '..', 'features', 'processed')\n",
    "\n",
    "# Ensure the 'processed' folder exists\n",
    "os.makedirs(processed_features_dir, exist_ok=True)\n",
    "\n",
    "# Save the TF-IDF features\n",
    "features_file_path = os.path.join(processed_features_dir, 'engineered_features.csv')\n",
    "pd.DataFrame(X.toarray()).to_csv(features_file_path, index=False)\n",
    "\n",
    "# Verify\n",
    "print(f\"\\nFeatures file saved: {os.path.exists(features_file_path)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e64c68",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Sentiment'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Sentiment'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Check class distribution in training data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSentiment\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalue_counts())\n",
      "File \u001b[1;32mc:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3896\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3898\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3795\u001b[0m     ):\n\u001b[0;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Sentiment'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8553d90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
